# Text classification w/ <img src="https://raw.githubusercontent.com/madewithml/images/master/images/tensorflow.png" width="25rem"> TensorFlow

ðŸš€ This project was created using the Made With ML [boilerplate](https://github.com/madewithml/boilerplate) template. Check it out to start creating your own ML applications.

## Set up
```
virtualenv -p python3.6 venv
source venv/bin/activate
pip install -r requirements.txt
pip install tensorflow==2.1.0
```

## Download embeddings
```bash
python text_classification/utils.py
```

## Training
```bash
python text_classification/train.py \
    --data-url https://raw.githubusercontent.com/madewithml/lessons/master/data/news.csv --lower --shuffle --use-glove
```

## Endpoints
```bash
uvicorn text_classification.app:app --host 0.0.0.0 --port 5000 --reload
GOTO: http://localhost:5000/docs
```

## Inference
### Scripts
```bash
python text_classification/predict.py --text 'The Canadian minister signed in the new federal law.'
```

### cURL
```
curl "http://localhost:5000/predict" \
    -X POST -H "Content-Type: application/json" \
    -d '{
            "inputs":[
                {
                    "text":"The Wimbledon tennis tournament starts next week!"
                },
                {
                    "text":"The Canadian minister signed in the new federal law."
                }
            ]
        }' | json_pp
```

### Requests
```python
import json
import requests

headers = {
    'Content-Type': 'application/json',
}

data = {
    "experiment_id": "latest",
    "inputs": [
        {
            "text": "The Wimbledon tennis tournament starts next week!"
        },
        {
            "text": "The Canadian minister signed in the new federal law."
        }
    ]
}

response = requests.post('http://0.0.0.0:5000/predict',
                         headers=headers, data=json.dumps(data))
results = json.loads(response.text)
print (json.dumps(results, indent=2, sort_keys=False))
```

## Streamlit
```bash
streamlit run text_classification/streamlit.py
GOTO: http://localhost:8501
```

## Tests
```bash
pytest
```

## Docker
1. Build image
```bash
docker build -t text-classification:latest -f Dockerfile .
```
2. Run container
```bash
docker run -d -p 5000:5000 -p 6006:6006 --name text-classification text-classification:latest
```

## Heroku
```
Set `WANDB_API_KEY` as an environment variable.
```

## Directory structure
```
text-classification/
â”œâ”€â”€ datasets/                           - datasets
â”œâ”€â”€ logs/                               - directory of log files
|   â”œâ”€â”€ errors/                           - error log
|   â””â”€â”€ info/                             - info log
â”œâ”€â”€ tests/                              - unit tests
â”œâ”€â”€ text_classification/                - ml scripts
|   â”œâ”€â”€ app.py                            - app endpoints
|   â”œâ”€â”€ config.py                         - configuration
|   â”œâ”€â”€ data.py                           - data processing
|   â”œâ”€â”€ models.py                         - model architectures
|   â”œâ”€â”€ predict.py                        - inference script
|   â”œâ”€â”€ streamlit.py                      - streamlit app
|   â”œâ”€â”€ train.py                          - training script
|   â””â”€â”€ utils.py                          - load embeddings
â”œâ”€â”€ wandb/                              - wandb experiment runs
â”œâ”€â”€ .dockerignore                       - files to ignore on docker
â”œâ”€â”€ .gitignore                          - files to ignore on git
â”œâ”€â”€ CODE_OF_CONDUCT.md                  - code of conduct
â”œâ”€â”€ CODEOWNERS                          - code owner assignments
â”œâ”€â”€ CONTRIBUTING.md                     - contributing guidelines
â”œâ”€â”€ Dockerfile                          - dockerfile to containerize app
â”œâ”€â”€ LICENSE                             - license description
â”œâ”€â”€ logging.json                        - logger configuration
â”œâ”€â”€ Procfile                            - process script for Heroku
â”œâ”€â”€ README.md                           - this README
â”œâ”€â”€ requirements.txt                    - requirementss
â”œâ”€â”€ setup.sh                            - streamlit setup for Heroku
â””â”€â”€ sweeps.yaml                         - hyperparameter wandb sweeps config
```

## Overfit to small subset
```
python text_classification/train.py \
    --data-url https://raw.githubusercontent.com/madewithml/lessons/master/data/news.csv --lower --shuffle --data-size 0.1 --num-epochs 3
```

## Experiments
1. Random, unfrozen, embeddings
```
python text_classification/train.py \
    --data-url https://raw.githubusercontent.com/madewithml/lessons/master/data/news.csv --lower --shuffle
```
2. GloVe, frozen, embeddings
```
python text_classification/train.py \
    --data-url https://raw.githubusercontent.com/madewithml/lessons/master/data/news.csv --lower --shuffle --use-glove --freeze-embeddings
```
3. GloVe, unfrozen, embeddings
```
python text_classification/train.py \
    --data-url https://raw.githubusercontent.com/madewithml/lessons/master/data/news.csv --lower --shuffle --use-glove
```

## Helpful docker commands
â€¢Â Build image
```
docker build -t madewithml:latest -f Dockerfile .
```

â€¢ Run container if using `CMD ["python", "app.py"]` or `ENTRYPOINT [ "/bin/sh", "entrypoint.sh"]`
```
docker run -p 5000:5000 --name madewithml madewithml:latest
```

â€¢ Get inside container if using `CMD ["/bin/bash"]`
```
docker run -p 5000:5000 -it madewithml /bin/bash
```

â€¢ Run container with mounted volume
```
docker run -p 5000:5000 -v $PWD:/root/madewithml/ --name madewithml madewithml:latest
```

â€¢ Other flags
```
-d: detached
-ti: interative terminal
```

â€¢ Clean up
```
docker stop $(docker ps -a -q)     # stop all containers
docker rm $(docker ps -a -q)       # remove all containers
docker rmi $(docker images -a -q)  # remove all images
```
